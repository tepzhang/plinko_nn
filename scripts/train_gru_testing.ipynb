{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from plinko.misc import data_utils\n",
    "from plinko.misc.simulation_dataset import SimulationDataset\n",
    "from plinko.model.predictor_gru import GRUPredictor\n",
    "\n",
    "def loaddata(run_indices = range(20), outdf = False):\n",
    "    df_ball = pd.read_feather('../data/simulations/sim_ball.feather')\n",
    "    df_env = pd.read_feather('../data/simulations/sim_environment.feather')\n",
    "    df_col = pd.read_feather('../data/simulations/sim_collisions.feather')\n",
    "\n",
    "    sim_data = data_utils.get_sim_data(df_ball, df_col)\n",
    "\n",
    "    # change this to dur <940 (max, 15s fall)\n",
    "    selected_runs = sim_data[(sim_data.num_collisions == 1)\n",
    "                             & (sim_data.duration < 50)\n",
    "                             & np.in1d(sim_data.run,run_indices)]\n",
    "    simulations, environments = data_utils.create_task_df(selected_runs, df_ball, df_env, append_t0 = False)\n",
    "    if outdf:\n",
    "        states, envs, simulations, environments = data_utils.to_tensors(simulations, environments, device, outdf)\n",
    "    else:\n",
    "        states, envs = data_utils.to_tensors(simulations, environments, device, outdf)\n",
    "    return states, envs, simulations, environments\n",
    "\n",
    "def get_logp_loss(gm, targets):\n",
    "    return -gm.log_p(targets).mean()\n",
    "\n",
    "def get_mu_mse_loss(gm, targets):\n",
    "    return F.mse_loss(gm.mu[:,:,0], targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,optimizer,simulations,dataset,savename = 'gru.model'):\n",
    "    # run SGD, with batchsize =64\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    max_t = simulations.t.max()\n",
    "    epochs = 100\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epochs + 1)):\n",
    "        epoch_loss = 0\n",
    "        epoch_mse_loss = 0\n",
    "        epoch_logp_loss = 0\n",
    "        for batch_i, batch in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            gm = model(batch['envs'], batch['states'], 0)\n",
    "            targets = batch['targets']\n",
    "\n",
    "            logp_loss = get_logp_loss(gm, targets)\n",
    "            mse_loss = 10 * get_mu_mse_loss(gm, targets)\n",
    "            loss = logp_loss + mse_loss\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss\n",
    "            epoch_logp_loss += logp_loss\n",
    "            epoch_mse_loss += mse_loss\n",
    "            losses.append((epoch, batch_i, float(loss)))\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch {} | logp: {} | mse: {} | total: {}'.format(epoch,\n",
    "                                                                     round(float(epoch_logp_loss), 4),\n",
    "                                                                     round(float(epoch_mse_loss), 4),\n",
    "                                                                     round(float(epoch_loss), 4)))\n",
    "\n",
    "    torch.save(model.state_dict(), savename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model(model,dataset,sim_df, env_df,modelname = 'gru1'):\n",
    "    dataloader = DataLoader(dataset, batch_size=len(envs), shuffle=True)\n",
    "    i = 0\n",
    "    for batch in dataloader:\n",
    "        i += 1\n",
    "        with torch.no_grad():\n",
    "            inter_gm, extra_gm, samples = model(batch['envs'], batch['states'][:, :1], 100)\n",
    "            targets = batch['targets'][:,1:101]\n",
    "            df_env, df_ball = data_utils.create_simdata_from_samples(samples, batch['envs'],sim_df, env_df)\n",
    "            \n",
    "#             df_ball[\"px\"] = df_ball.px.astype(float)\n",
    "#             df_ball[\"py\"] = df_ball.py.astype(float)\n",
    "#             df_ball.to_feather(os.path.join('../experiments/' + modelname + '/batch{}'.format(i) + 'samp.feather'))\n",
    "#             df_env.to_feather(os.path.join('../experiments/' + modelname + '/batch_{}'.format(i) + 'envs.feather'))\n",
    "            return df_ball, df_env\n",
    "\n",
    "def todf(env_batch):\n",
    "    columns = ['' '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "epsilon = sys.float_info.epsilon\n",
    "\n",
    "# load data\n",
    "states, envs, sim_df, env_df = loaddata(run_indices = range(20), outdf = True)\n",
    "dataset = SimulationDataset(envs, states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc176285e99488691c0e6389134b608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | logp: 506.6757 | mse: 4066.1643 | total: 4572.8394\n",
      "Epoch 5 | logp: -38.1786 | mse: 13.5641 | total: -24.6145\n",
      "Epoch 10 | logp: -1.6629 | mse: 27.889 | total: 26.2261\n",
      "Epoch 15 | logp: -120.8749 | mse: 5.5896 | total: -115.2853\n",
      "Epoch 20 | logp: -45.1586 | mse: 12.8062 | total: -32.3524\n",
      "Epoch 25 | logp: 1.1531 | mse: 37.1328 | total: 38.2859\n",
      "Epoch 30 | logp: -132.4912 | mse: 4.6821 | total: -127.8091\n",
      "Epoch 35 | logp: -70.6819 | mse: 13.9931 | total: -56.6888\n",
      "Epoch 40 | logp: -110.1565 | mse: 7.6125 | total: -102.544\n",
      "Epoch 45 | logp: -139.7759 | mse: 4.1942 | total: -135.5817\n",
      "Epoch 50 | logp: -158.36 | mse: 7.6127 | total: -150.7473\n",
      "Epoch 55 | logp: -73.8411 | mse: 8.5897 | total: -65.2514\n",
      "Epoch 60 | logp: -28.7351 | mse: 45.9127 | total: 17.1777\n",
      "Epoch 65 | logp: -42.1858 | mse: 27.8863 | total: -14.2994\n",
      "Epoch 70 | logp: -44.1223 | mse: 11.8533 | total: -32.2691\n",
      "Epoch 75 | logp: -133.9275 | mse: 9.6009 | total: -124.3265\n",
      "Epoch 80 | logp: -110.3693 | mse: 22.252 | total: -88.1173\n",
      "Epoch 85 | logp: -105.252 | mse: 34.5065 | total: -70.7456\n",
      "Epoch 90 | logp: -177.8425 | mse: 4.3542 | total: -173.4883\n",
      "Epoch 95 | logp: -102.0855 | mse: 13.3228 | total: -88.7627\n",
      "Epoch 100 | logp: -186.3089 | mse: 5.0432 | total: -181.2656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = GRUPredictor(env_size=envs.shape[1], state_size=2, num_gaussians=4).to(device)\n",
    "\n",
    "# train model;\n",
    "# optimizer = optim.SGD(model.parameters(), lr=.001)\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=.001)\n",
    "model = train_model(model, optimizer,sim_df, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8b6f704fd3ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# simulate from trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_ball\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# simulate from trained model\n",
    "df_ball, df_env = simulate_model(model, dataset,sim_df, env_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450000 entries, 0 to 449999\n",
      "Data columns (total 5 columns):\n",
      "simulation    450000 non-null object\n",
      "run           450000 non-null int64\n",
      "t             450000 non-null int64\n",
      "px            450000 non-null float64\n",
      "py            450000 non-null float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 17.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4500 entries, 0 to 4499\n",
      "Data columns (total 9 columns):\n",
      "triangle_x     4500 non-null float32\n",
      "triangle_y     4500 non-null float32\n",
      "triangle_r     4500 non-null float32\n",
      "rectangle_x    4500 non-null float32\n",
      "rectangle_y    4500 non-null float32\n",
      "rectangle_r    4500 non-null float32\n",
      "pentagon_x     4500 non-null float32\n",
      "pentagon_y     4500 non-null float32\n",
      "pentagon_r     4500 non-null float32\n",
      "dtypes: float32(9)\n",
      "memory usage: 158.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_ball[\"px\"] = df_ball.px.astype(float)\n",
    "df_ball[\"py\"] = df_ball.py.astype(float)\n",
    "\n",
    "# type(df_ball)\n",
    "df_ball.info()\n",
    "df_env.info()\n",
    "\n",
    "# print(df_ball[\"t\"])\n",
    "# print(df_ball[\"py\"] )\n",
    "# print(df_env['triangle_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ball.to_feather(os.path.join('../experiments/gru1/batch1_samp.feather'))\n",
    "df_env.to_feather(os.path.join('../experiments/gru1/batch1_envs.feather'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
